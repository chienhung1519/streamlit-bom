import streamlit as st
import pandas as pd
import sqlite3
import json
import os
import io
from datetime import datetime
from pathlib import Path

# =============================================================================
# è¨­å®š
# =============================================================================
DB_PATH = "database.db"
METADATA_PATH = "metadata.json"

# Metadata è¦è¿½è¹¤çš„æ¬„ä½
METADATA_COLUMNS = {
    "EE_BOM": [
        "Project_Name",
        "PARENT_DPN",
        "COMMODITY_CODE",
        "SUB_COMMODITY",
        "DPN",
        "ODM_PN",
        "MANUFACTURER",
        "MPN",
        "EM_DM",
        "Effective_Start_Date",
        "Effective_End_Date",
    ],
    "Cost_Adder_Logistic": [
        "Project_Name",
        "Parent_DPN",
        "Sub_Cost_Category",
        "Region",
    ],
}

# =============================================================================
# è³‡æ–™åº«æ“ä½œ
# =============================================================================
def get_db_connection():
    """å–å¾—è³‡æ–™åº«é€£ç·š"""
    conn = sqlite3.connect(DB_PATH)
    conn.row_factory = sqlite3.Row
    return conn


def init_database():
    """åˆå§‹åŒ–è³‡æ–™åº«ï¼ˆå¦‚æœ table ä¸å­˜åœ¨å‰‡å»ºç«‹ï¼‰"""
    conn = get_db_connection()
    cursor = conn.cursor()
    
    # æª¢æŸ¥ table æ˜¯å¦å­˜åœ¨ï¼Œè‹¥ä¸å­˜åœ¨å‰‡åœ¨ç¬¬ä¸€æ¬¡ä¸Šå‚³æ™‚å‹•æ…‹å»ºç«‹
    conn.close()


def table_exists(table_name: str) -> bool:
    """æª¢æŸ¥ table æ˜¯å¦å­˜åœ¨"""
    conn = get_db_connection()
    cursor = conn.cursor()
    cursor.execute(
        "SELECT name FROM sqlite_master WHERE type='table' AND name=?",
        (table_name,)
    )
    result = cursor.fetchone()
    conn.close()
    return result is not None


def create_table_from_df(table_name: str, df: pd.DataFrame):
    """æ ¹æ“š DataFrame å‹•æ…‹å»ºç«‹ table"""
    conn = get_db_connection()
    
    # åŠ å…¥ created_at æ¬„ä½
    df_with_timestamp = df.copy()
    df_with_timestamp["created_at"] = datetime.now().isoformat()
    
    # å»ºç«‹ tableï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
    df_with_timestamp.head(0).to_sql(table_name, conn, if_exists="ignore", index=False)
    
    conn.close()


def get_existing_data(table_name: str) -> pd.DataFrame:
    """å–å¾— table ä¸­æ‰€æœ‰è³‡æ–™"""
    if not table_exists(table_name):
        return pd.DataFrame()
    
    conn = get_db_connection()
    df = pd.read_sql(f"SELECT * FROM {table_name}", conn)
    conn.close()
    return df


def insert_data(table_name: str, df: pd.DataFrame) -> int:
    """
    æ’å…¥è³‡æ–™åˆ° tableï¼Œè·³éé‡è¤‡è³‡æ–™
    å›å‚³å¯¦éš›æ–°å¢çš„ç­†æ•¸
    """
    if df.empty:
        return 0
    
    conn = get_db_connection()
    
    # åŠ å…¥ created_at æ¬„ä½
    df_to_insert = df.copy()
    df_to_insert["created_at"] = datetime.now().isoformat()
    
    # å¦‚æœ table ä¸å­˜åœ¨ï¼Œå…ˆå»ºç«‹
    if not table_exists(table_name):
        df_to_insert.to_sql(table_name, conn, if_exists="replace", index=False)
        conn.close()
        return len(df_to_insert)
    
    # å–å¾—ç¾æœ‰è³‡æ–™ï¼ˆä¸å« created_atï¼‰
    existing_df = pd.read_sql(f"SELECT * FROM {table_name}", conn)
    
    # æ¯”è¼ƒç”¨çš„æ¬„ä½ï¼ˆæ’é™¤ created_atï¼‰
    compare_cols = [col for col in df.columns if col != "created_at"]
    
    # æ‰¾å‡ºä¸é‡è¤‡çš„è³‡æ–™
    if not existing_df.empty:
        # ç¢ºä¿åªæ¯”è¼ƒå…©é‚Šéƒ½æœ‰çš„æ¬„ä½
        common_cols = [col for col in compare_cols if col in existing_df.columns]
        
        # å°‡æ‰€æœ‰æ¬„ä½è½‰æ›ç‚ºå­—ä¸²ä»¥é¿å…è³‡æ–™é¡å‹ä¸ä¸€è‡´çš„å•é¡Œ
        df_compare = df[common_cols].astype(str)
        existing_compare = existing_df[common_cols].astype(str).drop_duplicates()
        
        # å°‡ df èˆ‡ existing åˆä½µï¼Œæ‰¾å‡ºæ–°è³‡æ–™
        merged = df_compare.merge(
            existing_compare,
            how="left",
            indicator=True
        )
        new_mask = merged["_merge"] == "left_only"
        new_df = df_to_insert[new_mask.values]
    else:
        new_df = df_to_insert
    
    # æ’å…¥æ–°è³‡æ–™
    if not new_df.empty:
        new_df.to_sql(table_name, conn, if_exists="append", index=False)
    
    conn.close()
    return len(new_df)


def query_data(table_name: str, filters: dict) -> pd.DataFrame:
    """
    æ ¹æ“šç¯©é¸æ¢ä»¶æŸ¥è©¢è³‡æ–™
    filters: {column_name: [value1, value2, ...], ...}
    """
    if not table_exists(table_name):
        return pd.DataFrame()
    
    conn = get_db_connection()
    
    # å»ºç«‹ SQL æŸ¥è©¢
    query = f"SELECT * FROM {table_name}"
    conditions = []
    params = []
    
    for col, values in filters.items():
        if values:  # åªè™•ç†æœ‰é¸æ“‡å€¼çš„æ¬„ä½
            placeholders = ", ".join(["?" for _ in values])
            conditions.append(f"{col} IN ({placeholders})")
            params.extend(values)
    
    if conditions:
        query += " WHERE " + " AND ".join(conditions)
    
    df = pd.read_sql(query, conn, params=params)
    conn.close()
    
    # ç§»é™¤ created_at æ¬„ä½ï¼ˆä¸éœ€è¦åœ¨å ±è¡¨ä¸­é¡¯ç¤ºï¼‰
    if "created_at" in df.columns:
        df = df.drop(columns=["created_at"])
    
    return df


# =============================================================================
# Metadata æ“ä½œ
# =============================================================================
def load_metadata() -> dict:
    """è¼‰å…¥ metadata.json"""
    if os.path.exists(METADATA_PATH):
        with open(METADATA_PATH, "r", encoding="utf-8") as f:
            return json.load(f)
    return {"EE_BOM": {}, "Cost_Adder_Logistic": {}}


def save_metadata(metadata: dict):
    """å„²å­˜ metadata.json"""
    with open(METADATA_PATH, "w", encoding="utf-8") as f:
        json.dump(metadata, f, ensure_ascii=False, indent=2)


def refresh_metadata():
    """é‡æ–°æƒæè³‡æ–™åº«ï¼Œæ›´æ–° metadata"""
    metadata = {"EE_BOM": {}, "Cost_Adder_Logistic": {}}
    
    conn = get_db_connection()
    
    for table_name, columns in METADATA_COLUMNS.items():
        if not table_exists(table_name):
            continue
        
        metadata[table_name] = {}
        
        for col in columns:
            # æª¢æŸ¥æ¬„ä½æ˜¯å¦å­˜åœ¨
            cursor = conn.cursor()
            cursor.execute(f"PRAGMA table_info({table_name})")
            table_columns = [row[1] for row in cursor.fetchall()]
            
            if col not in table_columns:
                continue
            
            # å–å¾— unique valuesï¼ŒæŒ‰ created_at ç”±æ–°åˆ°èˆŠæ’åº
            query = f"""
                SELECT DISTINCT {col}, MAX(created_at) as last_seen
                FROM {table_name}
                WHERE {col} IS NOT NULL AND {col} != ''
                GROUP BY {col}
                ORDER BY last_seen DESC
            """
            cursor.execute(query)
            results = cursor.fetchall()
            
            # åªä¿ç•™å€¼ï¼Œä¸ä¿ç•™ timestamp
            unique_values = [str(row[0]) for row in results]
            metadata[table_name][col] = unique_values
    
    conn.close()
    save_metadata(metadata)
    return metadata


# =============================================================================
# æª”åè§£æ
# =============================================================================
def parse_project_name(filename: str) -> str:
    """
    å¾æª”åè§£æ Project_Name
    è¦å‰‡ï¼šä»¥åº•ç·šåˆ†éš”ï¼Œå–ç¬¬ 3 å€‹æ¬„ä½ï¼ˆindex 2ï¼‰
    ç¯„ä¾‹ï¼š(Dell) SEBOM_Foxconn_Boss S2_PROD_Quote_20250411.xlsx â†’ Boss S2
    """
    # ç§»é™¤å‰¯æª”å
    name_without_ext = Path(filename).stem
    
    # ä»¥åº•ç·šåˆ†éš”
    parts = name_without_ext.split("_")
    
    if len(parts) >= 3:
        return parts[2]
    else:
        return name_without_ext  # å¦‚æœæ ¼å¼ä¸ç¬¦ï¼Œå›å‚³æ•´å€‹æª”å


# =============================================================================
# Streamlit UI
# =============================================================================
def main():
    st.set_page_config(
        page_title="BOM è³‡æ–™ç®¡ç†ç³»çµ±",
        page_icon="ğŸ“Š",
        layout="wide"
    )
    
    st.title("ğŸ“Š BOM è³‡æ–™ç®¡ç†ç³»çµ±")
    
    # å´é‚Šæ¬„é¸å–®
    page = st.sidebar.radio(
        "åŠŸèƒ½é¸æ“‡",
        ["ä¸Šå‚³è³‡æ–™", "ç”¢ç”Ÿå ±è¡¨"],
        index=0
    )
    
    if page == "ä¸Šå‚³è³‡æ–™":
        upload_page()
    else:
        report_page()


def upload_page():
    """ä¸Šå‚³è³‡æ–™é é¢"""
    st.header("ğŸ“¤ ä¸Šå‚³è³‡æ–™")
    
    st.info("""
    **ä½¿ç”¨èªªæ˜ï¼š**
    1. ä¸Šå‚³ Excel æª”æ¡ˆï¼ˆ.xlsxï¼‰
    2. æª”åæ ¼å¼ç¯„ä¾‹ï¼š`(Dell) SEBOM_Foxconn_Boss S2_PROD_Quote_20250411.xlsx`
    3. ç³»çµ±æœƒè‡ªå‹•è®€å– `EE_BOM` å’Œ `Cost_Adder_Logistic` å…©å€‹ Sheet
    """)
    
    uploaded_file = st.file_uploader(
        "é¸æ“‡ Excel æª”æ¡ˆ",
        type=["xlsx"],
        help="è«‹ä¸Šå‚³åŒ…å« EE_BOM å’Œ Cost_Adder_Logistic å·¥ä½œè¡¨çš„ Excel æª”æ¡ˆ"
    )
    
    if uploaded_file is not None:
        # è§£æ Project_Name
        project_name = parse_project_name(uploaded_file.name)
        
        st.write("---")
        st.subheader("ğŸ“‹ æª”æ¡ˆè³‡è¨Š")
        col1, col2 = st.columns(2)
        with col1:
            st.write(f"**æª”æ¡ˆåç¨±ï¼š** {uploaded_file.name}")
        with col2:
            st.write(f"**è§£æå‡ºçš„ Project_Nameï¼š** `{project_name}`")
        
        # è®€å– Excel
        try:
            excel_file = pd.ExcelFile(uploaded_file)
            sheet_names = excel_file.sheet_names
            
            # æª¢æŸ¥å¿…è¦çš„ Sheet
            required_sheets = ["EE_BOM", "Cost_Adder_Logistic"]
            missing_sheets = [s for s in required_sheets if s not in sheet_names]
            
            if missing_sheets:
                st.error(f"âŒ ç¼ºå°‘ä»¥ä¸‹å·¥ä½œè¡¨ï¼š{', '.join(missing_sheets)}")
                st.write(f"æª”æ¡ˆä¸­çš„å·¥ä½œè¡¨ï¼š{', '.join(sheet_names)}")
                return
            
            # è®€å–è³‡æ–™
            df_ee_bom = pd.read_excel(excel_file, sheet_name="EE_BOM")
            df_cost_adder = pd.read_excel(excel_file, sheet_name="Cost_Adder_Logistic")
            
            # åŠ å…¥ Project_Name æ¬„ä½
            df_ee_bom.insert(0, "Project_Name", project_name)
            df_cost_adder.insert(0, "Project_Name", project_name)
            
            # é¡¯ç¤ºé è¦½
            st.write("---")
            st.subheader("ğŸ‘€ è³‡æ–™é è¦½")
            
            tab1, tab2 = st.tabs(["EE_BOM", "Cost_Adder_Logistic"])
            
            with tab1:
                st.write(f"å…± {len(df_ee_bom)} ç­†è³‡æ–™")
                st.dataframe(df_ee_bom.head(10), use_container_width=True)
            
            with tab2:
                st.write(f"å…± {len(df_cost_adder)} ç­†è³‡æ–™")
                st.dataframe(df_cost_adder.head(10), use_container_width=True)
            
            # ä¸Šå‚³æŒ‰éˆ•
            st.write("---")
            if st.button("âœ… ç¢ºèªä¸Šå‚³", type="primary", use_container_width=True):
                with st.spinner("æ­£åœ¨è™•ç†è³‡æ–™..."):
                    # å„²å­˜åˆ°è³‡æ–™åº«
                    inserted_ee = insert_data("EE_BOM", df_ee_bom)
                    inserted_cost = insert_data("Cost_Adder_Logistic", df_cost_adder)
                    
                    # æ›´æ–° metadata
                    refresh_metadata()
                
                # é¡¯ç¤ºçµæœ
                st.success("âœ… ä¸Šå‚³å®Œæˆï¼")
                
                col1, col2 = st.columns(2)
                with col1:
                    st.metric(
                        label="EE_BOM",
                        value=f"{inserted_ee} ç­†æ–°å¢",
                        delta=f"å…± {len(df_ee_bom)} ç­†ï¼ˆ{len(df_ee_bom) - inserted_ee} ç­†é‡è¤‡ï¼‰"
                    )
                with col2:
                    st.metric(
                        label="Cost_Adder_Logistic",
                        value=f"{inserted_cost} ç­†æ–°å¢",
                        delta=f"å…± {len(df_cost_adder)} ç­†ï¼ˆ{len(df_cost_adder) - inserted_cost} ç­†é‡è¤‡ï¼‰"
                    )
        
        except Exception as e:
            st.error(f"âŒ è®€å–æª”æ¡ˆæ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{str(e)}")


def report_page():
    """ç”¢ç”Ÿå ±è¡¨é é¢"""
    st.header("ğŸ“Š ç”¢ç”Ÿå ±è¡¨")
    
    # è¼‰å…¥ metadata
    metadata = load_metadata()
    
    # é¸æ“‡ Table
    table_options = ["EE_BOM", "Cost_Adder_Logistic"]
    selected_table = st.selectbox(
        "é¸æ“‡è³‡æ–™è¡¨",
        table_options,
        help="é¸æ“‡è¦ç”¢ç”Ÿå ±è¡¨çš„è³‡æ–™è¡¨"
    )
    
    # æª¢æŸ¥æ˜¯å¦æœ‰è³‡æ–™
    if selected_table not in metadata or not metadata[selected_table]:
        st.warning(f"âš ï¸ {selected_table} å°šç„¡è³‡æ–™ï¼Œè«‹å…ˆä¸Šå‚³æª”æ¡ˆã€‚")
        return
    
    st.write("---")
    st.subheader("ğŸ” ç¯©é¸æ¢ä»¶")
    st.caption("å¯è¤‡é¸ï¼Œæ¬„ä½å…§ç‚º OR é‚è¼¯ï¼Œæ¬„ä½é–“ç‚º AND é‚è¼¯")
    
    # å‹•æ…‹ç”¢ç”Ÿç¯©é¸æ¢ä»¶
    filters = {}
    table_metadata = metadata[selected_table]
    
    # å°‡ç¯©é¸æ¢ä»¶åˆ†æˆå¤šæ¬„é¡¯ç¤º
    columns = list(table_metadata.keys())
    num_cols = 3
    
    for i in range(0, len(columns), num_cols):
        cols = st.columns(num_cols)
        for j, col in enumerate(columns[i:i+num_cols]):
            with cols[j]:
                options = table_metadata.get(col, [])
                selected = st.multiselect(
                    col,
                    options=options,
                    default=[],
                    help=f"é¸æ“‡ {col} çš„ç¯©é¸å€¼ï¼ˆå¯è¤‡é¸ï¼‰"
                )
                filters[col] = selected
    
    # æŸ¥è©¢èˆ‡ä¸‹è¼‰
    st.write("---")
    
    col1, col2 = st.columns([1, 1])
    
    with col1:
        preview_clicked = st.button("ğŸ‘ï¸ é è¦½è³‡æ–™", use_container_width=True)
    
    with col2:
        # å…ˆæŸ¥è©¢è³‡æ–™ä»¥ä¾¿ç”¢ç”Ÿä¸‹è¼‰æª”æ¡ˆ
        result_df = query_data(selected_table, filters)
        
        if not result_df.empty:
            # ç”¢ç”Ÿ Excel æª”æ¡ˆ
            output = io.BytesIO()
            with pd.ExcelWriter(output, engine="xlsxwriter") as writer:
                result_df.to_excel(writer, sheet_name=selected_table, index=False)
            excel_data = output.getvalue()
            
            # ä¸‹è¼‰æª”æ¡ˆåç¨±
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"{selected_table}_report_{timestamp}.xlsx"
            
            st.download_button(
                label="â¬‡ï¸ ä¸‹è¼‰ Excel å ±è¡¨",
                data=excel_data,
                file_name=filename,
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                use_container_width=True,
                type="primary"
            )
        else:
            st.button(
                "â¬‡ï¸ ä¸‹è¼‰ Excel å ±è¡¨",
                disabled=True,
                use_container_width=True,
                help="ç„¡ç¬¦åˆæ¢ä»¶çš„è³‡æ–™"
            )
    
    # é¡¯ç¤ºé è¦½
    if preview_clicked or "preview_shown" in st.session_state:
        st.write("---")
        st.subheader("ğŸ“‹ è³‡æ–™é è¦½")
        
        if result_df.empty:
            st.info("ğŸ” ç„¡ç¬¦åˆç¯©é¸æ¢ä»¶çš„è³‡æ–™")
        else:
            st.write(f"å…± {len(result_df)} ç­†è³‡æ–™ï¼ˆé¡¯ç¤ºå‰ 100 ç­†ï¼‰")
            st.dataframe(result_df.head(100), use_container_width=True)
            st.session_state["preview_shown"] = True


# =============================================================================
# ä¸»ç¨‹å¼å…¥å£
# =============================================================================
if __name__ == "__main__":
    init_database()
    main()